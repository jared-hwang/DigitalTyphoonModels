import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sn
from sklearn.metrics import f1_score, confusion_matrix, accuracy_score



'''
Num/max epochs: 20 
Batch size: 32 
Learning rate: 0.0001 
Split by: sequence 
Standardized: true
log_2023_05_08-07.44.02.txt
'''
train_loss = [1.1765559305082833, 0.9562483053783761, 0.8548224163915927, 0.7893410083679301, 0.7374880060831134, 0.6965565841950975, 0.6569473104745427, 0.6116731978265236, 0.5681558057703677, 0.5176868517043276, 0.4639855779038709, 0.41050742707900534, 0.3557467946229119, 0.30553775023792024, 0.25855481844225064, 0.21501893593451035, 0.18090134796944338, 0.15090812491584227, 0.1253184208145269, 0.10918175481349722]
test_loss = [1.0369523955834166, 0.9007221596461955, 0.8816757624046987, 0.8155090995163352, 0.7940691744403766, 0.8120446083745758, 0.8499494532310101, 0.8062660027664229, 0.9162353272761339, 0.8878266724381316, 0.950731013975052, 0.9776240033711942, 1.0911111062628958, 1.2614699608724957, 1.3186967013948798, 1.2994133648770887, 1.3820710097385, 1.4646246479210439, 1.6120802089774526, 1.8271662284563788]

'''
Num/max epochs: 100 
Batch size: 32 
Learning rate: 0.0001 
Split by: sequence 
Standardized: true
log_2023_05_07-17.13.39.txt
'''
# train_loss = [1.411255211363087, 1.284707069939177, 1.2524648511387062, 1.2294834064761453, 1.212099054574916, 1.1973887331671864, 1.185104228967538, 1.1760671723461413, 1.1664112566741547, 1.157803626387826, 1.149706421302947, 1.143122071276161, 1.1347448275183583, 1.1265720597578452, 1.1165006042964267, 1.1056959323406925, 1.0952359888098169, 1.0818596970134693, 1.0690521298010656, 1.0548512437314848, 1.040416228044908, 1.0233722721039933, 1.0090571115983826, 0.9939413181515357, 0.9787610330590744, 0.9659802672195718, 0.9564176486162396, 0.944948645041058, 0.9349247314396837, 0.9247280299184386, 0.9165063704424488, 0.9075635241761075, 0.900779330821226, 0.8918154065140413, 0.8872937128587735, 0.8812299639409003, 0.8722782664100287, 0.8696393332926244, 0.8643265012040914, 0.858778478253435, 0.854060338816785, 0.8495615672202702, 0.8433942845930931, 0.839421245041523, 0.8344732791544747, 0.8302738630408486, 0.8255448354735595, 0.8229381988750645, 0.8188806776960581, 0.814963358002635, 0.8112087702307309, 0.8073269544657528, 0.8019983281109735, 0.8001396407063728, 0.7978901536892906, 0.7952605841501283, 0.7902868764456468, 0.7903070877729169, 0.7841316260569238, 0.7800280842476928, 0.7777756846856435, 0.7731847055989288, 0.7719849861586147, 0.7688075247856485, 0.7643459387453005, 0.761603743638603, 0.7598420757558397, 0.7565607336186848, 0.754950347695967, 0.7497918158927225, 0.7472083051839691, 0.7451850760429436, 0.7421384547965734, 0.7400585361595812, 0.737470568279295, 0.7359974723626878, 0.7311764374164136, 0.7296911554581674, 0.7260364892116076, 0.7224474932934584, 0.7220153290473409, 0.7177005339266509, 0.7145072758853473, 0.7138043841272624, 0.7118981307975732, 0.7068286432457292, 0.70507552960672, 0.702231177592444, 0.699616846232276, 0.6980102072691146, 0.6935509444228786, 0.6922395841652176, 0.6874450085555016, 0.6856740325758668, 0.684461039142072, 0.6808152100438166, 0.6789333131617463, 0.6747922739910479, 0.6710952890456442, 0.6713072243303231]
# test_loss = [1.2830510299655964, 1.239361651271695, 1.2174196808676874, 1.202438392323723, 1.1878664482558903, 1.178158753728675, 1.1641691022120346, 1.1567477855039405, 1.1525183391508538, 1.1387748808185914, 1.1282843692399032, 1.1170139493356166, 1.1092433997682616, 1.1062823493653218, 1.089358396635297, 1.0748266490376677, 1.0946336336513007, 1.0480036687153917, 1.0583088215492078, 1.0250751310782327, 1.0982720781399515, 0.9866034607765117, 1.0023915884437296, 0.9549308880990007, 0.9855742614577735, 1.1489706428785316, 1.148669343298346, 1.0966770702877358, 0.9013192751818823, 1.017092463296672, 1.3013882734971232, 0.8836762511190295, 0.9014678512080332, 1.1344955794684748, 0.9879366115964902, 0.8692327140553343, 0.9488029260944499, 0.9020989419510513, 0.887066971790321, 1.1804912897658992, 0.8640232795166696, 0.8460046180714054, 0.8718500969091483, 0.8400510574454034, 0.9748020858365322, 0.8332117716743417, 0.8791228864881835, 0.8322092914379722, 0.8421598947609933, 0.847572950873109, 1.0306897930485668, 0.8386992805988535, 1.0059959089300403, 0.8246351179104865, 0.822990593189445, 1.0020937652997812, 0.9854007924360555, 0.9306038555881837, 0.8166197250770166, 0.8562425851852602, 0.8758940612722113, 0.8782755649622996, 0.793557244393048, 0.8302532548890266, 0.8348743549516058, 0.9748238891636518, 0.9465329731520917, 0.7911135800771194, 0.8381037370220155, 0.8397422149803588, 0.7945842274729578, 0.8009849285658671, 0.9885116430774092, 0.7831880625719968, 0.812247362184274, 0.8042979155403912, 1.0538711047218827, 0.7851611178978748, 0.9214772331708057, 0.7824935437584302, 0.7811813500179862, 0.8099238328714209, 0.8154536282196121, 0.8278523319520313, 0.7678535841849822, 0.854939013901556, 0.9102691128810165, 0.8941016691588842, 0.855114144298276, 0.8064688479054762, 0.8380929335716194, 0.869997941349796, 0.8300089016285506, 0.7696938431042356, 0.7867473626598563, 0.7772824521615929, 0.9955716352028177, 1.0511152217528934, 0.8410060379442899, 0.8134150661517243]

"""
Num/max epochs: 100 
Batch size: 16 
Learning rate: 0.0001 
Split by: sequence 
Standardized: true
log_2023_05_06-15.15.49.txt
"""
# train_loss = [1.374477796984178, 1.2547095214396025, 1.2156497638145587, 1.1851412626362745, 1.1641454045614381, 1.142615756582626, 1.123094056424811, 1.0981005201162124, 1.0684373966790597, 1.0355712383427376, 1.0055945652866474, 0.983859515145347, 0.9638038836494475, 0.9457118824296193, 0.9300428282115941, 0.9144583080208701, 0.9037194404794027, 0.89250257720696, 0.8818437249404945, 0.8732978967860469, 0.8632566304972986, 0.856090906293616, 0.8481359191387876, 0.8412338263546268, 0.8350840778990835, 0.8270613116986435, 0.820348986818379, 0.8146106189249079, 0.8089809324511548, 0.8033657130482663, 0.798195275276152, 0.7941433137976269, 0.7867285076581212, 0.7828179918235099, 0.7782777920057882, 0.7724243795167907, 0.7679930162715504, 0.762587191547468, 0.757904081177603, 0.7534226381757274, 0.749407618876841, 0.7438826594115843, 0.7406293533536672, 0.7339984733722107, 0.7287625983403153, 0.7264591177065982, 0.7204300146067083, 0.715203969232772, 0.7107064384652148, 0.7074901506221177, 0.701883913057719, 0.69744066000237, 0.6932525396782209, 0.689758747737252, 0.6845882863260403, 0.6783210546828341, 0.6738409272275543, 0.6707198384965164, 0.6653390564942862, 0.6598921105030693, 0.6543671739279889, 0.6500655500542082, 0.6452446907519058, 0.6401117394436177, 0.636673308845084, 0.6311761023975935, 0.6268121185643044, 0.6206473334480651, 0.6151445424565561, 0.6117733470735292, 0.6068329916339288, 0.6004748215543922, 0.5941565172935387, 0.5891462141225583, 0.5851802020293798, 0.5788699200343561, 0.5731659314327424, 0.5669269177973201, 0.5595508545034841, 0.5562600509434349, 0.5486198588598722, 0.544015526233899, 0.5356791308538937, 0.5306984587452195, 0.5231347995158945, 0.5197855524483048, 0.5125185662858663, 0.5036594887556645, 0.4991856190722754, 0.4927730115845763, 0.48602831742553126, 0.4789773238878593, 0.4724782823849363, 0.46590717841712725, 0.45694815668211125, 0.4523195921539087, 0.4441537051808013, 0.4389809263867558, 0.42917070517466444, 0.42314598578796125]
# test_loss = [1.2893031322660014, 1.2337772197743353, 1.2090570160321108, 1.182666552198203, 1.1759439445184496, 1.1685313730783025, 1.1393849982105657, 1.2290678415364882, 1.1435816706403243, 1.0314567599388946, 1.0188439100846252, 1.1980199829769256, 1.0199036201907752, 0.9753741374529578, 0.9729594956378286, 0.9168613104580751, 0.9720411165698032, 0.9920085701049027, 1.272215108645862, 0.9337641111520203, 0.9039027596570393, 0.9070961337184181, 0.8745995447407532, 0.8812726366931866, 0.9467405185729345, 0.8654015616992528, 0.8547712628995804, 0.8493762583402836, 0.8397611770638783, 0.8702235020933045, 0.8686464118196958, 0.863504264298356, 0.8271339131400737, 0.8836194855151228, 0.8707494920720134, 0.8306711296639679, 0.833866291712723, 0.8338225701602561, 0.8448353485962404, 0.8036536250630038, 0.7972366607260373, 0.9055419248089228, 0.8223913935305549, 0.8182483073199217, 0.8205089544810086, 1.051404613014038, 0.8191967873264094, 0.8262215920908833, 0.8557772300787629, 0.8444358803827877, 0.798713919334488, 0.8081957027274367, 0.7925376312206622, 0.8197467161724388, 0.8015757258832413, 0.7847230297907578, 0.8919881975460179, 0.9431227643650899, 0.8996861113323238, 0.8208521743453847, 0.8161220537263157, 1.0318888219762286, 0.8129817742671082, 0.80756676884676, 0.8098949067703937, 0.8203181543522159, 0.8841032057146739, 0.837121954138393, 0.865496666901473, 0.9940639522424596, 0.8988603905586456, 0.8730996620788113, 1.1171900436784075, 0.8409477719160461, 0.8615775360631874, 0.8727484302016604, 0.8496672076772619, 0.9543272807473081, 0.9321225582336236, 0.952057818453827, 1.0967852623401682, 0.9181690837437675, 1.09871169309799, 1.2308521076409435, 0.9749510028583241, 0.9599021263965729, 0.9389016748536484, 0.8894664330506414, 0.8806089547068147, 0.8942825472321527, 0.9791466525963599, 0.9804808421010857, 1.2182403604430982, 0.9021819414883285, 1.0957802639714203, 1.0412541553335604, 1.2563844626759948, 0.9879238797993752, 1.73264426714378, 1.0026188453763674]

# plt.plot(train_loss, label='train')
# plt.plot(test_loss, label='test')
# plt.legend()
# plt.show()


cm_matrix =[[7016, 2361,  365,  116,  250],
 [2458, 3819, 1327,  729,  392],
 [ 310, 1276, 1402, 1873,  312,],
 [  56,  277,  827, 8669,   22],
 [ 206,  110 ,  44,   3, 3718]]

df_cm = pd.DataFrame(cm_matrix, index=[i + 2 for i in range(5)],
                         columns=[i + 2 for i in range(5)])

plt.figure(figsize=(12, 7))
sn.heatmap(df_cm, annot=True, fmt='g')
plt.show()
# plt.savefig(str(savepath / 'logs' / f'resnet_confusion_matrix_{timestring}.png'))


def build_confusion_matrix(predicted_labels, truth_labels, num_classes, timestring, savepath):
    # Build confusion matrix
    cf_matrix = confusion_matrix(truth_labels, predicted_labels)
    df_cm = pd.DataFrame(cf_matrix, index=[i + 2 for i in range(num_classes)],
                         columns=[i + 2 for i in range(num_classes)])

    plt.figure(figsize=(12, 7))
    sn.heatmap(df_cm, annot=True, fmt='g')
    plt.savefig(str(savepath / 'logs' / f'resnet_confusion_matrix_{timestring}.png'))

    # Save normalized confusion matrix
    plt.clf()
    df_cm = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1)[:, None], index=[i + 2 for i in range(num_classes)],
                         columns=[i + 2 for i in range(num_classes)])
    sn.heatmap(df_cm, annot=True, fmt='g')
    plt.savefig(str(savepath / 'logs' / f'resnet_confusion_matrix_norm_{timestring}.png'))

    return cf_matrix
